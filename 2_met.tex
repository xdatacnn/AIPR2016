\section{Convolutional neural networks}\label{sec:met}
Synapses enable nerve cells to connect to thousands of other neurons, combine signals, and push the integrated information forward. Early research by Hubel and Wiesel [1] on the catâ€™s visual cortex showed that neurons propagate information through complex cell organizations called receptive fields [2]. These fields work similarly to filters for the stimuli coming from previous retinal layers, and allow information from 125 million photoreceptors to be successfully processed and pushed forward to 1 million ganglion cells along the visual processing path. These biological filters can be framed in an algorithmic motif that exploits the strong spatially local correlation present in digital images in learning tasks. As an example of such algorithms, convolutional neural networks (CNNs) have been successfully used in pattern recognition because CNN can learn a hierarchy of features by building high-level features from low-level ones, thereby automating the process of feature construction [3, 4], much differently from traditional approaches.

In this section, we introduce the proposed Convolutional Neural Networks algorithms used for scientific image exploration and understanding under four modalities
, which consists of three main

why different science problems are being attached by different algorithms? Are there differences in the architecture of these different algorithms?

On the convergence of classification algorithms for

\subsection{Matconvnet}

\subsubsection{Neuromophic computation}


\subsection{TensorFlow}
