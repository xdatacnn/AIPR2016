\section{Convolutional neural networks}\label{sec:met}
Synapses enable nerve cells to connect to thousands of other neurons, combine signals, and push the integrated information forward. Early research by Hubel and Wiesel [1] on the catâ€™s visual cortex showed that neurons propagate information through complex cell organizations called receptive fields [2]. These fields work similarly to filters for the stimuli coming from previous retinal layers, and allow information from 125 million photoreceptors to be successfully processed and pushed forward to 1 million ganglion cells along the visual processing path. These biological filters can be framed in an algorithmic motif that exploits the strong spatially local correlation present in digital images in learning tasks. As an example of such algorithms, convolutional neural networks (CNNs) have been successfully used in pattern recognition because CNN can learn a hierarchy of features by building high-level features from low-level ones, thereby automating the process of feature construction [3, 4], much differently from traditional approaches.

In this section, we describe the Convolutional Neural Networks algorithms used for scientific image exploration and understanding of four imaging modalities, earlier described in Section~\ref{sec:mat}.

- why different science problems are being attached by different algorithms? Are there differences in the architecture of these different algorithms?

%On the convergence of classification algorithms for

\subsection{Matconvnet}%venkat/chao/dani
%From joao
The architecture of Convolutional Neural Networks (CNN) depend on a
large number of parameters, obtained from the data and derived weights,
found during a through search over the hyperparameter space. The
memory footprint to compute and store CNN models demand research
on methods to adapt CNN to energy efficient devices. This work focuses
on data reduction schemes and net weight representations in order to
accurately classify scientific data from simulations. Our scheme reduces
double-format values to one byte,maintaining classification accuracy
above 98\%.

\subsubsection{Neuromophic computation}%dani

\subsection{TensorFlow} %flaromdan

The TensorFlow arquiteture to create the CNN in this work is based in the AlexNet\ref{alexnet}.  We used a CNN with two convLayers (CL), two poolLayers (PL) and two fully connected layers (FC). The features of the last FC are use for image retrieval. The number of parameters of all layers is 571,648 and the number of pameters of the FC is 467,520. Table~\ref{tab:layers} shows the TensorFlow arquiteture including the output and filter size of each layer.

\begin{table}
\centering \caption{TensorFlow CNN structure used.} \label{tab:layers}
 \normalsize
     \begin{tabular}{c c c c}
         \hline
         Layer No. & Layer Type      & Output Size & Filter Size \\ \hline
         1         & Input           & 16 x 16 x 1 &  ---\\
         2         & Convolutional   & 16 x 16 x 64 & 5 x 5 \\
         3         & Max-pooling     & 8 x 8 x 64 & 2 x 2 \\
         4         & Convolutional   & 8 x 8 x 64 &  5 x 5 \\
         5         & Max-pooling     & 4 x 4 x 64 &  2 x 2 \\
         6         & Fully connected & 382 x 1 & --- \\
         7         & Fully connected & 192 x 1 & --- \\
         \hline
     \end{tabular}
 \end{table}
